{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the data and preprocess the data\n",
    "def read_preprocess(filename):\n",
    "    f = open(filename)\n",
    "    raw_data = f.readlines()\n",
    "    \n",
    "    point_lst = []\n",
    "    for ele in raw_data:\n",
    "        point = []\n",
    "        for value in ele.split():\n",
    "            point.append(float(value))\n",
    "        point_lst.append(point)\n",
    "        \n",
    "    return np.array(point_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './zip.train'\n",
    "training_array = read_preprocess(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './zip.test'\n",
    "testing_array = read_preprocess(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_array[:,1:]\n",
    "Y_train = training_array[:,0]\n",
    "\n",
    "X_test = testing_array[:,1:]\n",
    "Y_test = testing_array[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7291, 256)\n",
      "(7291,)\n",
      "(2007, 256)\n",
      "(2007,)\n"
     ]
    }
   ],
   "source": [
    "# test to see how many data points in train set and test set and see the shape of the data\n",
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "print X_test.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions for calculating the distances and k-NN implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dist() function will calculate the distance of each test point to all the train points and store the values in dist_lst.\n",
    "\n",
    "knn( ) function is the implementation of kNN.\n",
    "\n",
    "score() function will calculate the accuracy of each kNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(X_test , X_train):\n",
    "    dist_lst = []\n",
    "    for point in X_test:\n",
    "        dist_lst.append(np.sum(np.power(point - X_train, 2), axis = 1))\n",
    "    return np.array(dist_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k, dist_lst):\n",
    "    \n",
    "    prediction = []\n",
    "    \n",
    "    index = np.argsort(dist_lst, axis = 1)\n",
    "    \n",
    "    knn_points =  index[:, :k]\n",
    "    \n",
    "    for row in Y_train[knn_points]:\n",
    "        prediction.append(Counter(row).most_common()[0][0])\n",
    "    \n",
    "    return np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(predictions, Y_test):\n",
    "    return np.sum([predictions == Y_test])/float(Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist_lst = dist(X_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row, there are 7291 values. \n",
    "\n",
    "For example, we can know that in row 0, these 7291 values mean the distances of the first test point to all data points in train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2007, 7291)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_lst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kone_predictions = knn(1, dist_lst)\n",
    "ktwo_predictions = knn(2, dist_lst)\n",
    "kthree_predictions = knn(3, dist_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sklearn library to build the confusion matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many predctions are with label '0'\n",
    "kone_predictions[kone_predictions==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355   0   2   0   0   0   0   1   0   1]\n",
      " [  0 255   0   0   6   0   2   1   0   0]\n",
      " [  6   1 183   2   1   0   0   2   3   0]\n",
      " [  3   0   2 154   0   5   0   0   0   2]\n",
      " [  0   3   1   0 182   1   2   2   1   8]\n",
      " [  2   1   2   4   0 145   2   0   3   1]\n",
      " [  0   0   1   0   2   3 164   0   0   0]\n",
      " [  0   1   1   1   4   0   0 139   0   1]\n",
      " [  5   0   1   6   1   1   0   1 148   3]\n",
      " [  0   0   1   0   2   0   0   4   1 169]]\n"
     ]
    }
   ],
   "source": [
    "kone_confusion_matrix= confusion_matrix(Y_test, kone_predictions, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "print kone_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code, we can see that the number of predictions with label '0' is 371. The 1-NN model predicted correctly that 355 are label '0', but 16 (6+3+2+5) points in test set are incorrectly predicted as label '0'.\n",
    "So the accuracy of label '0' is:$\\frac{355}{371}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.957  0.     0.01   0.     0.     0.     0.     0.007  0.     0.005]\n",
      " [ 0.     0.977  0.     0.     0.03   0.     0.012  0.007  0.     0.   ]\n",
      " [ 0.016  0.004  0.943  0.012  0.005  0.     0.     0.013  0.019  0.   ]\n",
      " [ 0.008  0.     0.01   0.922  0.     0.032  0.     0.     0.     0.011]\n",
      " [ 0.     0.011  0.005  0.     0.919  0.006  0.012  0.013  0.006  0.043]\n",
      " [ 0.005  0.004  0.01   0.024  0.     0.935  0.012  0.     0.019  0.005]\n",
      " [ 0.     0.     0.005  0.     0.01   0.019  0.965  0.     0.     0.   ]\n",
      " [ 0.     0.004  0.005  0.006  0.02   0.     0.     0.927  0.     0.005]\n",
      " [ 0.013  0.     0.005  0.036  0.005  0.006  0.     0.007  0.949  0.016]\n",
      " [ 0.     0.     0.005  0.     0.01   0.     0.     0.027  0.006  0.914]]\n"
     ]
    }
   ],
   "source": [
    "print np.around(kone_confusion_matrix/np.sum(kone_confusion_matrix, axis = 0, dtype='float'), decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94369706028898859"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(kone_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355   0   3   0   0   0   0   0   0   1]\n",
      " [  0 259   0   0   3   0   1   1   0   0]\n",
      " [ 10   1 178   1   1   0   0   2   5   0]\n",
      " [  3   0   2 154   0   3   0   0   2   2]\n",
      " [  0   3   4   0 173   1   2   2   1  14]\n",
      " [  4   1   2   8   0 137   0   0   4   4]\n",
      " [  4   0   1   0   2   2 160   0   1   0]\n",
      " [  0   2   1   1   4   0   0 133   1   5]\n",
      " [  5   0   3   1   0   1   0   1 153   2]\n",
      " [  1   0   1   0   2   0   0   4   1 168]]\n"
     ]
    }
   ],
   "source": [
    "ktwo_confusion_matrix= confusion_matrix(Y_test, ktwo_predictions)\n",
    "print ktwo_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.929  0.     0.015  0.     0.     0.     0.     0.     0.     0.005]\n",
      " [ 0.     0.974  0.     0.     0.016  0.     0.006  0.007  0.     0.   ]\n",
      " [ 0.026  0.004  0.913  0.006  0.005  0.     0.     0.014  0.03   0.   ]\n",
      " [ 0.008  0.     0.01   0.933  0.     0.021  0.     0.     0.012  0.01 ]\n",
      " [ 0.     0.011  0.021  0.     0.935  0.007  0.012  0.014  0.006  0.071]\n",
      " [ 0.01   0.004  0.01   0.048  0.     0.951  0.     0.     0.024  0.02 ]\n",
      " [ 0.01   0.     0.005  0.     0.011  0.014  0.982  0.     0.006  0.   ]\n",
      " [ 0.     0.008  0.005  0.006  0.022  0.     0.     0.93   0.006  0.026]\n",
      " [ 0.013  0.     0.015  0.006  0.     0.007  0.     0.007  0.911  0.01 ]\n",
      " [ 0.003  0.     0.005  0.     0.011  0.     0.     0.028  0.006  0.857]]\n"
     ]
    }
   ],
   "source": [
    "print np.around(ktwo_confusion_matrix/np.sum(ktwo_confusion_matrix, axis = 0, dtype='float'), decimals= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93173891380169405"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(ktwo_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355   0   2   0   0   0   0   0   1   1]\n",
      " [  0 258   0   0   3   0   2   1   0   0]\n",
      " [  8   0 183   1   1   0   0   2   3   0]\n",
      " [  3   0   2 153   0   6   0   1   0   1]\n",
      " [  0   2   0   0 182   2   2   2   1   9]\n",
      " [  5   0   3   3   0 144   0   0   1   4]\n",
      " [  3   1   1   0   2   0 163   0   0   0]\n",
      " [  0   1   1   1   4   0   0 138   1   1]\n",
      " [  4   0   1   4   0   1   0   1 152   3]\n",
      " [  1   0   0   0   3   0   0   4   1 168]]\n"
     ]
    }
   ],
   "source": [
    "kthree_confusion_matrix= confusion_matrix(Y_test, kthree_predictions)\n",
    "print kthree_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.937  0.     0.01   0.     0.     0.     0.     0.     0.006  0.005]\n",
      " [ 0.     0.985  0.     0.     0.015  0.     0.012  0.007  0.     0.   ]\n",
      " [ 0.021  0.     0.948  0.006  0.005  0.     0.     0.013  0.019  0.   ]\n",
      " [ 0.008  0.     0.01   0.944  0.     0.039  0.     0.007  0.     0.005]\n",
      " [ 0.     0.008  0.     0.     0.933  0.013  0.012  0.013  0.006  0.048]\n",
      " [ 0.013  0.     0.016  0.019  0.     0.941  0.     0.     0.006  0.021]\n",
      " [ 0.008  0.004  0.005  0.     0.01   0.     0.976  0.     0.     0.   ]\n",
      " [ 0.     0.004  0.005  0.006  0.021  0.     0.     0.926  0.006  0.005]\n",
      " [ 0.011  0.     0.005  0.025  0.     0.007  0.     0.007  0.95   0.016]\n",
      " [ 0.003  0.     0.     0.     0.015  0.     0.     0.027  0.006  0.898]]\n"
     ]
    }
   ],
   "source": [
    "print np.around(kthree_confusion_matrix/np.sum(kthree_confusion_matrix, axis = 0, dtype='float'), decimals= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94469357249626307"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(kthree_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
