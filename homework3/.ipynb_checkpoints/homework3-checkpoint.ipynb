{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mustererkennung Aufgabe 3\n",
    "Yu He, Remi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the data and preprocess the data\n",
    "def read_preprocess(filename):\n",
    "    f = open(filename)\n",
    "    raw_data = f.readlines()\n",
    "    \n",
    "    point_lst = []\n",
    "    for ele in raw_data:\n",
    "        point = []\n",
    "        for value in ele.split():\n",
    "            point.append(float(value))\n",
    "        point_lst.append(point)\n",
    "        \n",
    "    return np.array(point_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './zip.train'\n",
    "training_array = read_preprocess(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './zip.test'\n",
    "testing_array = read_preprocess(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_digit_three = training_array[:,0] - 3 == 0\n",
    "train_digit_five = training_array[:,0] - 5 == 0\n",
    "train_digit_seven = training_array[:,0] - 7 == 0\n",
    "train_digit_eight = training_array[:,0] - 8 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {3:train_digit_three, 5:train_digit_five, 7:train_digit_seven, 8:train_digit_eight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_digit_three = testing_array[:,0] - 3 == 0\n",
    "test_digit_five = testing_array[:,0] - 5 == 0\n",
    "test_digit_seven = testing_array[:,0] - 7 == 0\n",
    "test_digit_eight = testing_array[:,0] - 8 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {3:test_digit_three, 5:test_digit_five, 7:test_digit_seven, 8:test_digit_eight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_trainset(digit_one, digit_two, train):\n",
    "    digit_one_array = train[train_dict[digit_one]]\n",
    "    digit_two_array = train[train_dict[digit_two]]\n",
    "    train_set = np.concatenate((digit_one_array, digit_two_array), axis = 0)\n",
    "    X = train_set[:,1:]\n",
    "    Y = train_set[:,0]\n",
    "   \n",
    "    num_data = X.shape[0]\n",
    "    bias = np.ones((num_data,1))\n",
    "    X = np.concatenate((bias, X), axis = 1)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def gen_testset(digit_one, digit_two, test):\n",
    "    digit_one_array = test[test_dict[digit_one]]\n",
    "    digit_two_array = test[test_dict[digit_two]]\n",
    "    test_set = np.concatenate((digit_one_array, digit_two_array), axis = 0)  \n",
    "    X = test_set[:,1:]\n",
    "    Y = test_set[:,0]\n",
    "    num_data = X.shape[0]\n",
    "    bias = np.ones((num_data,1))\n",
    "    X = np.concatenate((bias, X), axis = 1)   \n",
    "    \n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function predict_one() takes only one test data point as input. So we need to use loop, if we want to obtain the accuracy of the model using the entire test data set.\n",
    "\n",
    "Function predict() takes the entire test data set as input. Consider the situation that we have a N * M matrix as the test set. N represents the number of data points, M represents the number of features. So the covariance matrix will be in shape of M * M. The result of $ (X - \\mu)*\\Sigma^{-1}*(X - \\mu)^{T} $ will be a N * N matrix. Each value at the diagnoal of the matrix is the scalar we need for calculating the probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function predict_one() was use for only one data point in the test set. If it is used for many data points, loop and list shall be used for accuracy calculation, which also means it will take more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gaussian_classifier:\n",
    "    def fit(self, X, y):\n",
    "        self.class_one = np.unique(y)[0]\n",
    "        self.class_two = np.unique(y)[1]\n",
    "        \n",
    "        class_one_X = (X[y==self.class_one])\n",
    "        class_two_X = (X[y==self.class_two])\n",
    "        \n",
    "        self.covariance1 = np.cov(class_one_X, rowvar = False)\n",
    "        self.covariance2 = np.cov(class_two_X, rowvar = False)\n",
    "                \n",
    "        self.mean1 = np.mean(class_one_X, axis = 0)\n",
    "        self.mean2 = np.mean(class_two_X, axis = 0)\n",
    "        \n",
    "    def predict_one(self, x):\n",
    "        factor1 = 1.0/ np.sqrt(np.linalg.norm(2*np.pi*self.covariance1))\n",
    "        factor2 = 1.0/ np.sqrt(np.linalg.norm(2*np.pi*self.covariance2))\n",
    "        \n",
    "        index1 = -1/2 * np.dot(np.dot(x - self.mean1,np.linalg.pinv(self.covariance1)), (x - self.mean1).T)\n",
    "        index2 = -1/2 * np.dot(np.dot(x - self.mean2,np.linalg.pinv(self.convariance2)), (x - self.mean2).T)\n",
    "        \n",
    "        prob1 = factor1*np.exp(index1)\n",
    "        prob2 = factor2*np.exp(index2)\n",
    "        \n",
    "        if prob1 >= prob2:\n",
    "            return self.class_one\n",
    "        else:\n",
    "            return self.class_two\n",
    "        \n",
    "    def predict(self, X):\n",
    "        factor1 = 1.0/ np.sqrt(np.linalg.norm(2*np.pi*self.covariance1))\n",
    "        factor2 = 1.0/ np.sqrt(np.linalg.norm(2*np.pi*self.covariance2))\n",
    "        \n",
    "        index1 = -1/2 * np.dot(np.dot(X - self.mean1,np.linalg.pinv(self.covariance1)), (X - self.mean1).T)\n",
    "        index2 = -1/2 * np.dot(np.dot(X - self.mean2,np.linalg.pinv(self.covariance2)), (X - self.mean2).T)\n",
    "        \n",
    "        prob1 = factor1*np.exp(np.diag(index1))\n",
    "        prob2 = factor2*np.exp(np.diag(index2))\n",
    "        \n",
    "        self.result = np.zeros((X.shape[0]))\n",
    "        self.result[prob1 - prob2 >= 0] = self.class_one\n",
    "        self.result[prob1 - prob2 < 0] = self.class_two\n",
    "        \n",
    "    def multifit(self, X,y):\n",
    "        self.class_one = np.unique(y)[0]\n",
    "        self.class_two = np.unique(y)[1]\n",
    "        self.class_three = np.unique(y)[2]\n",
    "        self.class_four = np.unique(y)[3]\n",
    "        \n",
    "        class_one_X = (X[y==self.class_one])\n",
    "        class_two_X = (X[y==self.class_two])\n",
    "        class_three_X = (X[y==self.class_three])\n",
    "        class_four_X = (X[y==self.class_four])\n",
    "        \n",
    "        self.covariance1 = np.cov(class_one_X, rowvar = False)\n",
    "        self.covariance2 = np.cov(class_two_X, rowvar = False)\n",
    "        self.covariance3 = np.cov(class_three_X, rowvar = False)\n",
    "        self.covariance4 = np.cov(class_four_X, rowvar = False)\n",
    "\n",
    "        self.mean1 = np.mean(class_one_X, axis = 0)\n",
    "        self.mean2 = np.mean(class_two_X, axis = 0)\n",
    "        self.mean3 = np.mean(class_three_X, axis = 0)\n",
    "        self.mean4 = np.mean(class_four_X, axis = 0)\n",
    "\n",
    "    def multipredit(self, X):\n",
    "        factor1 = 1.0/ np.sqrt(np.linalg.norm(2*np.pi*self.covariance1))\n",
    "        factor2 = 1.0/ np.sqrt(np.linalg.norm(2*np.pi*self.covariance2))\n",
    "        factor3 = 1.0/ np.sqrt(np.linalg.norm(2*np.pi*self.covariance3))\n",
    "        factor4 = 1.0/ np.sqrt(np.linalg.norm(2*np.pi*self.covariance4))\n",
    "\n",
    "        \n",
    "        \n",
    "        index1 = -1/2 * np.dot(np.dot(X - self.mean1,np.linalg.pinv(self.covariance1)), (X - self.mean1).T)\n",
    "        index2 = -1/2 * np.dot(np.dot(X - self.mean2,np.linalg.pinv(self.covariance2)), (X - self.mean2).T)\n",
    "        index3 = -1/2 * np.dot(np.dot(X - self.mean3,np.linalg.pinv(self.covariance3)), (X - self.mean3).T)\n",
    "        index4 = -1/2 * np.dot(np.dot(X - self.mean4,np.linalg.pinv(self.covariance4)), (X - self.mean4).T)\n",
    "        \n",
    "        prob1 = factor1*np.exp(np.diag(index1)).reshape(1,X.shape[0])\n",
    "        prob2 = factor2*np.exp(np.diag(index2)).reshape(1,X.shape[0])\n",
    "        prob3 = factor2*np.exp(np.diag(index3)).reshape(1,X.shape[0])\n",
    "        prob4 = factor2*np.exp(np.diag(index4)).reshape(1,X.shape[0])\n",
    "                \n",
    "        prob = np.concatenate((prob1, prob2, prob3, prob4), axis = 0)\n",
    "                \n",
    "        self.result = np.argmax(prob, axis = 0)\n",
    "        \n",
    "        # we need to put self.result[self.result == 0] = self.class_one at the end,\n",
    "        # because if it is first executed, it will have conflict with digit 8.\n",
    "        # all the values==3 in matrix result will finally be 8 at last\n",
    "\n",
    "        self.result[self.result == 1] = self.class_two\n",
    "        self.result[self.result == 2] = self.class_three\n",
    "        self.result[self.result == 3] = self.class_four\n",
    "        self.result[self.result == 0] = self.class_one\n",
    "\n",
    "    def score(self, y):\n",
    "        return sum(self.result - y == 0)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit 3,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = gen_trainset(3,5, training_array)\n",
    "X_test, Y_test = gen_testset(3,5, testing_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gaussian_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92331288343558282"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.score(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit 3,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92971246006389774"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = gen_trainset(3, 7, training_array)\n",
    "X_test, Y_test = gen_testset(3,7 ,testing_array)\n",
    "gc = gaussian_classifier()\n",
    "gc.fit(X_train, Y_train)\n",
    "gc.predict(X_test)\n",
    "gc.score(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit 3, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84337349397590367"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = gen_trainset(3, 8, training_array)\n",
    "X_test, Y_test = gen_testset(3,8 ,testing_array)\n",
    "gc = gaussian_classifier()\n",
    "gc.fit(X_train, Y_train)\n",
    "gc.predict(X_test)\n",
    "gc.score(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit 5,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9315960912052117"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = gen_trainset(5, 7, training_array)\n",
    "X_test, Y_test = gen_testset(5, 7 ,testing_array)\n",
    "gc = gaussian_classifier()\n",
    "gc.fit(X_train, Y_train)\n",
    "gc.predict(X_test)\n",
    "gc.score(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit 5, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87423312883435578"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = gen_trainset(5, 8, training_array)\n",
    "X_test, Y_test = gen_testset(5, 8,testing_array)\n",
    "gc = gaussian_classifier()\n",
    "gc.fit(X_train, Y_train)\n",
    "gc.predict(X_test)\n",
    "gc.score(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit 7, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83706070287539935"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = gen_trainset(7, 8, training_array)\n",
    "X_test, Y_test = gen_testset(7, 8,testing_array)\n",
    "gc = gaussian_classifier()\n",
    "gc.fit(X_train, Y_train)\n",
    "gc.predict(X_test)\n",
    "gc.score(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit 3,5,7,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, Y_train1 = gen_trainset(3,5, training_array)\n",
    "X_test1, Y_test1 = gen_testset(3,5, testing_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, Y_train2 = gen_trainset(7,8, training_array)\n",
    "X_test2, Y_test2 = gen_testset(7,8, testing_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1,X_train2), axis = 0)\n",
    "X_test = np.concatenate((X_test1, X_test2), axis = 0)\n",
    "Y_train = np.concatenate((Y_train1, Y_train2), axis = 0)\n",
    "Y_test = np.concatenate((Y_test1, Y_test2), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83881064162754304"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = gaussian_classifier()\n",
    "gc.multifit(X_train, Y_train)\n",
    "gc.multipredit(X_test)\n",
    "gc.score(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
